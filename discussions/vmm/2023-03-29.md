---
title: "VMM WG, March 29, 2023"
tags: unikraft, vmm
datetime: 2023-03-29T08:30:00+02:00
location: Online, Discord (https://bit.ly/UnikraftDiscord), the `#monkey-business` voice channel
teams:
- vmm
participants:
- AndreiT
- PaulU
- RăzvanD
- PaulV
- Marc
---

## :dart: Agenda

- Status update
- Next steps

## :closed_book: Discussions

### Hyper-V

PV: Last time I had issues with receiving.
I figured out why.
You need to configure a filter, which is by default enabled preventing packets from reaching.

PV: This message sent from the guest to the host to unblock the filter doesn't work.

PV: I had this issue with the rx_filter function.
And now I'm stuck.

PV: I checked the code in DPDK and in FreeBSD to see if I'm doing something wrong.
It doesn't seem I'm doing something wrong.

PV: Querying for the MAC address works.
It's a function `hn_rnds_execute()` that you pass a payload, with different payloads.

PV: When it sends the RNDS packet to the network management device, I get an acknowledge packet.
It's a "status OK" packet.

MR: Are you sure this response is expected?
Maybe it's just silently doing its work.

PV: I'm doing the same flow for other types of RNDS messages.
The way the code is written in the DPDK driver shows this is what it expects.

MR: Have a running, working driver to see what happens.
Such as the FreeBSD driver or DPDK.

RD: Look into extensive logging on the Hyper-V side.

PV: I investigated and there are no extensive logging on Hyper-V, probably due to security reasons.

### VMware

PU: I didn't have any updates.

PU: I need to investigate the issue with 0.8 version (0.7 works) by doing a git bisect approach.

PU: There is a question of what to do next.

RD: An idea would be to go the the vmxnet driver or block device support.

MR: Test it with Unikraft and Linux and WRK.
And see what is the performance.

MR: If the performance is lower, I would then move using the paravirtualized device.

PU: On the block device, there is need for support from VMware.

PU: The paravirtualized driver requests PCIexpress support.

### vsock

AT: I managed to merge everything together on 0.10: mmio, booting and vsock.
In order to test vsock.
There are errors with mmio, on the initialization part.

AT: There is an assert triggered by Unikraft.
And warnings sent out by Firecracker.

AT: I'm also working with a Firecracker build from scratch.

## :wrench: TODOs and Decisions

RD: Ask Răzvan Pricop about updates on block device support on Hyper-V.

RD: Discuss with maintainers about PCI Express support.

PV: Run a working instance of a networking driver on Hyper (DPDK, FreeBSD) and see what are differences in behavior.

PU: Look into the issue with 0.7 and 0.8.

AT: Debug the vsock issues with Firecracker.
